{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer_finetune.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "CQ2dYFRfjGPm",
        "rcSk2sy0ksOd"
      ],
      "machine_shape": "hm",
      "mount_file_id": "1MjNu4SextkaGMOjvSd0ur-NuXbjhl1xV",
      "authorship_tag": "ABX9TyMIJ+qztO36tc2jcxSEVHWF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumikey/bts-gpt2/blob/main/gpt2simple_finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GPT-2 Fine-tuning practise\n",
        "\n",
        "Code adapted from this video: https://www.youtube.com/watch?v=DNLebQ_vYiw"
      ],
      "metadata": {
        "id": "CaEVBgCpi_Eq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Installing Dependencies & Mounting Google Drive"
      ],
      "metadata": {
        "id": "CQ2dYFRfjGPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set tensor flow version with magic command\n",
        "%tensorflow_version 1.x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "741QDfPJyvpw",
        "outputId": "43907872-567d-455b-ed87-d05ed9d909b3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive and set accept\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhtrXLJtu-ju",
        "outputId": "812befc1-1972-43ce-e0ce-7bb2d6a5ca24"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install transformers\n",
        "!pip3 install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAWrG6fgjLf5",
        "outputId": "715f5ed1-adf3-487e-b75b-770326ef06a5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.14.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 10.5 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 49.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 50.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 513 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 41.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install gpt-2-simple\n",
        "!pip install gpt-2-simple"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaQ7kuotlknr",
        "outputId": "84c58ab6-aac8-4fbb-d6d6-ad78d816ae50"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gpt-2-simple\n",
            "  Downloading gpt_2_simple-0.8.1.tar.gz (26 kB)\n",
            "Collecting tensorflow>=2.5.1\n",
            "  Downloading tensorflow-2.7.0-cp37-cp37m-manylinux2010_x86_64.whl (489.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 489.6 MB 22 kB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (1.19.5)\n",
            "Collecting toposort\n",
            "  Downloading toposort-1.7-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.22.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.13.3)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.4.0)\n",
            "Collecting tensorboard~=2.6\n",
            "  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 53.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.37.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (12.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.10.0.2)\n",
            "Collecting keras<2.8,>=2.7.0rc0\n",
            "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 35.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.12.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.42.0)\n",
            "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
            "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
            "\u001b[K     |████████████████████████████████| 463 kB 56.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.1.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.5.1->gpt-2-simple) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (1.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (57.4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gpt-2-simple) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gpt-2-simple) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gpt-2-simple) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gpt-2-simple) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (3.1.1)\n",
            "Building wheels for collected packages: gpt-2-simple\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpt-2-simple: filename=gpt_2_simple-0.8.1-py3-none-any.whl size=24576 sha256=09d45ee59f038bf63efc07ecc9da4d2eecc20742fc6f9b156bfe115c83525a8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/89/8a/f5de6944286d1ac2658b0caa7eae3c8cda50f770cdc957217f\n",
            "Successfully built gpt-2-simple\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, toposort, tensorflow, gpt-2-simple\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: Keras 2.3.1\n",
            "    Uninstalling Keras-2.3.1:\n",
            "      Successfully uninstalled Keras-2.3.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 1.15.2\n",
            "    Uninstalling tensorflow-1.15.2:\n",
            "      Successfully uninstalled tensorflow-1.15.2\n",
            "Successfully installed gpt-2-simple-0.8.1 keras-2.7.0 tensorboard-2.7.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0 toposort-1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Old way of setting up text data, now defunct\n"
      ],
      "metadata": {
        "id": "FHCgf7F3kCcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # read file from google drive\n",
        "# file = open(\"/content/drive/MyDrive/bts_project/merged_clean.txt\")\n",
        "# # read the text file and make string\n",
        "# tune_text = file.read()"
      ],
      "metadata": {
        "id": "X-NeugqcjLwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(tune_text[:200])"
      ],
      "metadata": {
        "id": "yiCjjvPdjL1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Setup GPT-2 Simple & setup fine_tuning text path"
      ],
      "metadata": {
        "id": "rcSk2sy0ksOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import and alias\n",
        "import gpt_2_simple as gpt2"
      ],
      "metadata": {
        "id": "RlPrNLHDk9Bb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download relevant model, begin with small version\n",
        "gpt2.download_gpt2(model_name=\"355M\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "of0FuslKl4oV",
        "outputId": "aa31930e-3f51-41b5-862f-6dc8362520be"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 444Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 3.45Mit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 726Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:54, 26.3Mit/s]                                 \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 805Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 3.27Mit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 4.37Mit/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Change the path of below file depending on where stored in google drive*"
      ],
      "metadata": {
        "id": "0OhKoNXewKuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set file / path.\n",
        "# change depending on where you store your file in google drive\n",
        "file_name = \"/content/drive/MyDrive/Corpus/merged_clean.txt\""
      ],
      "metadata": {
        "id": "FYgDXjGlmjG9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Finetune"
      ],
      "metadata": {
        "id": "uuGlC19DnJi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#start session\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "#finetune sess with parameters\n",
        "gpt2.finetune(sess,\n",
        "              dataset= file_name,\n",
        "              model_name='355M',\n",
        "              steps=100,  #number of epochs want to run\n",
        "              restore_from='fresh',\n",
        "              run_name='run1', #what to name the saved model\n",
        "              print_every=10, #show loss and avg loss after every 10 epochs\n",
        "              sample_every=50, #print a sample on the screen after every 20 epochs\n",
        "              save_every=20,  #save the model after every 20 epochs\n",
        "              #use_memory_saving_gradients = True, # recommended for larger models\n",
        "              only_train_transformer_layers = True, # recommended for larger models\n",
        "              accumulate_gradients = 1) # recommended for larger models #used for 355M model train\n",
        "              #reuse = True)  #used for 355M model train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InkR4-ZtnC7G",
        "outputId": "9236fbab-df8c-406d-ead9-b476b95f3264"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For larger models, the recommended finetune() parameters are:\n",
            "\tuse_memory_saving_gradients = True\n",
            "\tonly_train_transformer_layers = True\n",
            "\taccumulate_gradients = 1\n",
            "\n",
            "Loading checkpoint models/355M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/355M/model.ckpt\n",
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:18<00:00, 18.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 3246411 tokens\n",
            "Training...\n",
            "[10 | 14.23] loss=2.71 avg=2.71\n",
            "[20 | 20.93] loss=2.85 avg=2.78\n",
            "Saving checkpoint/run1/model-20\n",
            "[30 | 34.27] loss=2.76 avg=2.77\n",
            "[40 | 40.99] loss=2.64 avg=2.74\n",
            "Saving checkpoint/run1/model-40\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1058: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "[50 | 54.15] loss=2.96 avg=2.79\n",
            "======== SAMPLE 1 ========\n",
            " at the moment, we are a bit of a mess, the situation is bad all around us, and I cannot just stop myself from doing something more. It is time, as I said, that you see it all!\n",
            "\n",
            "\"But what is that?\" I asked, very angry.\n",
            " \"That! That is something very important\", answered he who gave the order.\n",
            "I felt my mouth drop open. He shook his head, and I saw it now--a picture! What sort of a picture! The big black man sat in his chair, and stood in front of the little white woman. Oh! I loved him! She had a heart of gold! She was beautiful! But if I were a slave I should be like the other girls of the castle, of course, but here I am, the big black man!\n",
            "\"What is to be done,\" said he, \"with the black man?\"\n",
            "\n",
            "\"It is to be killed\", I answered.\n",
            "\n",
            "\"What are you doing in the forest, then? Is there something to be done?\"\n",
            "\n",
            "\"What are you talking about--for the reason that I cannot stop myself from killing the black man?\" I asked.\n",
            "\n",
            "\"Yes, of course it is a hard thing to do, but I have to do something to save the black man\", said he.\n",
            "\n",
            "\"What is to do with the white, that is?\"\n",
            "\n",
            "\"It is impossible\", I answered. And I thought of all the other little princesses, and how they all stood next to him, all of them beautiful. I felt my heart swell, and saw the black man standing before me, the little white woman standing at his side; and I said to him,\n",
            "\n",
            "\"That is not a picture!\" I said, and shook my head. \"All I want is for you to see how beautiful the little girl is, and to see that there is not any in the wood. I want this girl to be your equal.\"\n",
            "\n",
            "But he shook his head, and I looked at him again, and thought of the little white princess before me, all of her beauty--all of her sweetness--all of her beautiful looks--all of the many beautiful things in the wood. I thought of the black woman, and he said, \"I wish so very much to see this big black woman, and to see that she will be my equal; but first I will make a deal with the witches.\"\n",
            "\n",
            "Then I said,\n",
            "\n",
            "\"I want some tea and some biscuits. I don't want to be alone with the black man; so let me get some of that, and I'll go and fetch my tea and biscuits.\"\n",
            "\n",
            "As I went on, the white witch started to laugh, and said, \"Well, I must tell you the truth, I have just the picture for him of the little white princess sitting in the wood with her friend, and then the black man standing over the little white woman with the black man.\"\n",
            "\n",
            "\"It is the picture; but there has to be a reason for the black man's looking at her, and the red man must not look at the picture.\"\n",
            "\n",
            "\"I won't tell you!\" answered the black man, shaking his head. \"But I saw that the witch had made up a big deal about the big black handkerchief in the witches' box. She must have looked at it to-day. So why are you telling me that?\"\n",
            "\n",
            "\"It is for the purpose of explaining,\" answered I, \"that it was just what I had been seeking for.\"\n",
            "\n",
            "The witch laughed, and said, \"That is so! If it isn't then how can this witch be your equal? And let us see that there is not a witch left in the wood, and let us see how beautiful the little princess is, and how I may be to-day my equal!\"\n",
            "\n",
            "\"What can be said to that?\" I asked them.\n",
            "\n",
            "\"The same thing, yes,\" said the witch; \"but there is something more in it.\"\n",
            "\n",
            "Then I said to her,\n",
            "\"I know that you are trying to explain it all to me--but I will tell you one thing only: there is not a witch left in the wood, and if she has seen something that is not in the witches' box, she must look again. There is quite enough of the witches' box to account for the big black handkerchief, and the black man; and if she does, she must look again. If she does, it will be a very good thing to-night to-morrow to-morrow to-morrow to-night to-morrow, then, to-morrow, she will look again. And when the big black handkerchief comes in, then, to-morrow, she must look again. And, besides, the black woman would be my equal, and the little white woman my equal. I have found for you one\n",
            "\n",
            "[60 | 84.03] loss=3.25 avg=2.86\n",
            "Saving checkpoint/run1/model-60\n",
            "[70 | 97.95] loss=3.64 avg=2.98\n",
            "[80 | 104.64] loss=2.59 avg=2.93\n",
            "Saving checkpoint/run1/model-80\n",
            "[90 | 117.57] loss=2.97 avg=2.93\n",
            "[100 | 124.27] loss=2.80 avg=2.92\n",
            "Saving checkpoint/run1/model-100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Generate Text"
      ],
      "metadata": {
        "id": "CSgu2BDHpmDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test generate text prediction -- no prompt\n",
        "gpt2.generate(sess, run_name='run1')"
      ],
      "metadata": {
        "id": "Jaza9owkppUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt to be given to the generation\n",
        "prompt = \"\"\"The king had drunk far too much wine.\"\"\""
      ],
      "metadata": {
        "id": "qTTSnpZFRuCB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# time to generate a proper prediction with a prompt\n",
        "gen_text = gpt2.generate(sess,\n",
        "              length=200,  #number of tokens to generate\n",
        "              temperature=0.7, #takes value beteen 0 and 1. Determines randomness\n",
        "              prefix=prompt,# prompt to start generation\n",
        "              nsamples=1, #number of samples want to produce\n",
        "              batch_size=1,\n",
        "              top_k=40  #number of tokens to take into account when generating\n",
        "              )"
      ],
      "metadata": {
        "id": "juD6MCzTqCcR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29c68df7-8e8d-4b7c-9352-d51304b5bcf7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The king had drunk far too much wine.\n",
            "\n",
            "The king was about to go to bed, when his daughter-in-law, the queen, called out to him: \"My father, will you give me a little bottle of wine, for my mother-in-law, the queen, wants to know if she can see you?\"\n",
            "\n",
            "\"I will give her a little bottle,\" answered the king.\n",
            "\n",
            "\"What is the use of this? Will you take the bottle and put it in your mouth?\"\n",
            "\n",
            "\"What use?\" said the king.\n",
            "\n",
            "\"Nothing,\" replied the queen.\n",
            "\n",
            "\"Then let us go into the hall of the queen, and there we will drink together.\"\n",
            "\n",
            "\"No, nothing of that,\" said the king, \"my father wants to see you.\"\n",
            "\n",
            "\"What do you want to see me, my father?\"\n",
            "\n",
            "\"I want to see a certain man, a certain young woman,\" answered the king.\n",
            "\n",
            "\"My father will permit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UNbGHfOKvnW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lImkWe3dEe_W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}